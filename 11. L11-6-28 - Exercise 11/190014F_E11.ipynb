{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h3><center>EN2550 Exercise 11 - CNN and Transfer Learning</center></h3>**\n",
    "*Name - Abeysinghe W.A.M.S.Y*\n",
    "<br>\n",
    "*Index no - 190014F*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**. Implement the LeNet5 network, as discussed in class, for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape:  (60000, 32, 32)\n",
      "train_labels.shape:  (60000,)\n",
      "test_images.shape: (10000, 32, 32)\n",
      "test_labels.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Padding\n",
    "paddings = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "train_images = tf.pad(train_images, paddings, constant_values=0)\n",
    "test_images = tf.pad(test_images, paddings, constant_values=0)\n",
    "\n",
    "print('train_images.shape: ', train_images.shape)\n",
    "print('train_labels.shape: ', train_labels.shape)\n",
    "print('test_images.shape:', test_images.shape)\n",
    "print('test_labels.shape:', test_labels.shape)\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "train_images = tf.dtypes.cast(train_images, tf.float32)\n",
    "test_images = tf.dtypes.cast(test_images, tf.float32)\n",
    "train_images, test_images = train_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x000002768397B520>>\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.2115 - accuracy: 0.9353\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0680 - accuracy: 0.9788\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 35s 18ms/step - loss: 0.0487 - accuracy: 0.9848\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0382 - accuracy: 0.9879\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0325 - accuracy: 0.9900\n",
      "313/313 - 2s - loss: 0.0407 - accuracy: 0.9876 - 2s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6,(5,5),activation = 'relu',input_shape = (32,32,1)))\n",
    "model.add(layers.AveragePooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16,(5,5),activation = 'relu'))\n",
    "model.add(layers.AveragePooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120,activation = 'relu'))\n",
    "model.add(layers.Dense(84,activation = 'relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model.summary)\n",
    "model.fit(train_images,train_labels,epochs = 5)\n",
    "test_loss, test_accuracy = model.evaluate(test_images,test_labels,verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**. Implement a CNN for CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CIFAR10\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x00000276888AACE0>>\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 78s 47ms/step - loss: 1.5563 - accuracy: 0.4298\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.1974 - accuracy: 0.5743\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.0276 - accuracy: 0.6384\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.9172 - accuracy: 0.6789\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.8328 - accuracy: 0.7092\n",
      "313/313 - 5s - loss: 0.9320 - accuracy: 0.6794 - 5s/epoch - 15ms/step\n",
      "0.6794000267982483\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(5,5),activation = 'relu',input_shape = (32,32,3)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation = 'relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model.summary)\n",
    "\n",
    "model.fit(train_images,train_labels,epochs = 5)\n",
    "test_loss, test_accuracy = model.evaluate(test_images,test_labels,verbose = 2)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**. For the MINST dataset, implement the following network (call it model_base):\n",
    "C 3×3, 32\n",
    "M 2×2\n",
    "C 3×3, 64\n",
    "M 2×2\n",
    "C 3×3, 64\n",
    "F\n",
    "D 64\n",
    "D 10\n",
    "C: convolution layer, M: max pooling, F: flatttening, D: dense layer. All activations\n",
    "are ReLu. The last layer has no activation function. All strides are 1, except in M,\n",
    "where the stride is 2. Train this network for 2 epochs and save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape:  (60000, 32, 32)\n",
      "train_labels.shape:  (60000,)\n",
      "test_images.shape: (10000, 32, 32)\n",
      "test_labels.shape: (10000,)\n",
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x000002768AAFD1E0>>\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.1390 - accuracy: 0.9579\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0434 - accuracy: 0.9867\n",
      "313/313 - 3s - loss: 0.0269 - accuracy: 0.9905 - 3s/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Padding\n",
    "paddings = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "train_images = tf.pad(train_images, paddings, constant_values=0)\n",
    "test_images = tf.pad(test_images, paddings, constant_values=0)\n",
    "\n",
    "print('train_images.shape: ', train_images.shape)\n",
    "print('train_labels.shape: ', train_labels.shape)\n",
    "print('test_images.shape:', test_images.shape)\n",
    "print('test_labels.shape:', test_labels.shape)\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "train_images = tf.dtypes.cast(train_images, tf.float32)\n",
    "test_images = tf.dtypes.cast(test_images, tf.float32)\n",
    "train_images, test_images = train_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0\n",
    "\n",
    "model_base = models.Sequential()\n",
    "model_base.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (32,32,1)))\n",
    "model_base.add(layers.MaxPool2D((2,2)))\n",
    "model_base.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model_base.add(layers.MaxPool2D((2,2)))\n",
    "model_base.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "\n",
    "model_base.add(layers.Flatten())\n",
    "model_base.add(layers.Dense(64,activation = 'relu'))\n",
    "model_base.add(layers.Dense(10))\n",
    "\n",
    "model_base.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model_base.summary)\n",
    "\n",
    "model_base.fit(train_images,train_labels,epochs = 2)\n",
    "test_loss, test_accuracy = model_base.evaluate(test_images,test_labels,verbose = 2)\n",
    "model_base.save_weights('saved_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**. Create a second network with exactly the same structure as in 3. Call this model_lw.\n",
    "Load the weights saved in 3. Train for two epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x000002768AAFDFF0>>\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1390 - accuracy: 0.9581\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0424 - accuracy: 0.9869\n",
      "313/313 - 3s - loss: 0.0288 - accuracy: 0.9896 - 3s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_lw = models.Sequential()\n",
    "model_lw.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (32,32,1)))\n",
    "model_lw.add(layers.MaxPool2D((2,2)))\n",
    "model_lw.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model_lw.add(layers.MaxPool2D((2,2)))\n",
    "model_lw.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "\n",
    "model_lw.add(layers.Flatten())\n",
    "model_lw.add(layers.Dense(64,activation = 'relu'))\n",
    "model_lw.add(layers.Dense(10))\n",
    "\n",
    "model_lw.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model_lw.summary)\n",
    "\n",
    "model_lw.fit(train_images,train_labels,epochs = 2)\n",
    "test_loss, test_accuracy = model_lw.evaluate(test_images,test_labels,verbose = 2)\n",
    "model_lw.save('saved_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**. Load this model using keras.models.load_model. Call this model_ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 15, 15, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 121,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "313/313 - 3s - loss: 0.0288 - accuracy: 0.9896 - 3s/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02881079725921154, 0.9896000027656555]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "model_ld = keras.models.load_model('saved_model/')\n",
    "print(model_ld.summary())\n",
    "model_ld.evaluate(test_images,test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**. Transfer learning: Load the saved model except the last layer. Connect a fresh dense\n",
    "layer of 10 output nodes. Train for two epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.functional.Functional object at 0x00000276866800D0>>\n",
      "Epoch 1/3\n",
      "1875/1875 - 44s - loss: 0.0797 - accuracy: 0.9771 - 44s/epoch - 23ms/step\n",
      "Epoch 2/3\n",
      "1875/1875 - 77s - loss: 0.0260 - accuracy: 0.9921 - 77s/epoch - 41ms/step\n",
      "Epoch 3/3\n",
      "1875/1875 - 80s - loss: 0.0204 - accuracy: 0.9935 - 80s/epoch - 43ms/step\n",
      "313/313 - 6s - loss: 0.0302 - accuracy: 0.9914 - 6s/epoch - 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03019169345498085, 0.9914000034332275]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_inputs = model_ld.layers[0].input\n",
    "base_outputs = model_ld.layers[-2].output\n",
    "output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "new_model = keras.Model(inputs=base_inputs, outputs = output)\n",
    "new_model.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(new_model.summary)\n",
    "\n",
    "new_model.fit(train_images,train_labels,epochs = 3,verbose = 2)\n",
    "new_model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**. Fine tuning: Load the saved model. Make the loaded layers non-trainable. Repeat\n",
    "the process in 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 - 13s - loss: 0.2837 - accuracy: 0.9411 - 13s/epoch - 7ms/step\n",
      "Epoch 2/3\n",
      "1875/1875 - 11s - loss: 0.0275 - accuracy: 0.9923 - 11s/epoch - 6ms/step\n",
      "Epoch 3/3\n",
      "1875/1875 - 13s - loss: 0.0220 - accuracy: 0.9934 - 13s/epoch - 7ms/step\n",
      "313/313 - 2s - loss: 0.0259 - accuracy: 0.9912 - 2s/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025896890088915825, 0.9911999702453613]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer learning\n",
    "model_for_tl =keras.models.load_model('saved_model/')\n",
    "model_for_tl.trainable = False\n",
    "for layer in model_for_tl.layers:\n",
    "    assert layer.trainable == False\n",
    "\n",
    "base_inputs = model_for_tl.layers[0].input\n",
    "base_outputs = model_for_tl.layers[-2].output\n",
    "output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "new_model = keras.Model(inputs=base_inputs, outputs = output)\n",
    "new_model.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "\n",
    "new_model.fit(train_images,train_labels,epochs = 3,verbose = 2)\n",
    "new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8**. Load a pre-trained ResNet model, e.g., keras.applications.resnet_v2.ResNet50V2. Connect\n",
    "an output layer of 5 nodes. Feed arrays of random numbers as input images and\n",
    "transfer learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tl=keras.applications.resnet_v2.ResNet50V2()\n",
    "\n",
    "model_tl.trainable=False\n",
    "for layer in model_tl.layers:\n",
    "    assert layer.trainable==False\n",
    "\n",
    "base_innputs=model_tl.layers[0].input\n",
    "base_ouputs=model_tl.layers[-2].output\n",
    "output=layers.Dense(5)(base_ouputs)\n",
    "\n",
    "model_tl=keras.Model(inputs=base_innputs,outputs=output)\n",
    "model_tl.compile(optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "print(model_tl.summary())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5ca2acd7cfffe1ba430de162f968a242c109575471a8c149f67da86ddb07b1e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
